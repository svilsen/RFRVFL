% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ae_rwnn.R
\name{ae_rwnn}
\alias{ae_rwnn}
\alias{ae_rwnn.formula}
\title{Auto-encoder pre-trained random weight neural networks}
\usage{
ae_rwnn(
  formula,
  data = NULL,
  N_hidden = c(),
  lambda = NULL,
  method = "l1",
  control = list()
)

\method{ae_rwnn}{formula}(
  formula,
  data = NULL,
  N_hidden = c(),
  lambda = NULL,
  method = "l1",
  control = list()
)
}
\arguments{
\item{formula}{A \link{formula} specifying features and targets used to estimate the parameters of the output layer.}

\item{data}{A data-set (either a \link{data.frame} or a \link[tibble]{tibble}) used to estimate the parameters of the output layer.}

\item{N_hidden}{A vector of integers designating the number of neurons in each of the hidden layers (the length of the list is taken as the number of hidden layers).}

\item{lambda}{The penalisation constant used when training the output layer.}

\item{method}{The penalisation type used in the auto-encoder (either \code{"l1"} or \code{"l2"}).}

\item{control}{A list of additional arguments passed to the \link{control_rwnn} function.}
}
\value{
An \link{RWNN-object}.
}
\description{
Set-up and estimate weights of a random weight neural network using an auto-encoder for unsupervised pre-training of the hidden weights.
}
\examples{
N_hidden <- 10

## Using L1-norm in the auto-encoder (sparse solution)
ae_rwnn(y ~ ., data = example_data, N_hidden = N_hidden, lambda = 0.2, method = "l1")

## Using L2-norm in the auto-encoder (non-sparse solution)
ae_rwnn(y ~ ., data = example_data, N_hidden = N_hidden, lambda = 0.2, method = "l2")
}
