% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tuning_hyperparameters.R
\name{tune_hyperparameters}
\alias{tune_hyperparameters}
\title{Hyper-parameter tuning}
\usage{
tune_hyperparameters(
  method,
  X,
  y,
  folds = 10,
  hyperparameters = list(),
  control = list(),
  trace = 0
)
}
\arguments{
\item{method}{The RWNN method in need to hyper parameter optimisation.}

\item{X}{A matrix of observed features used to train the parameters of the output layer.}

\item{y}{A vector of observed targets used to train the parameters of the output layer.}

\item{folds}{The number of folds used in k-fold cross-validation.}

\item{hyperparameters}{A list of sequences of hyper-parameters.}

\item{control}{A list of additional arguments passed to the \link{control_rwnn} function.}

\item{trace}{A numeric indicating how often a trace of should be shown (default is 0).}
}
\value{
Either an \link{RWNN-object} or \link{ERWNN-object}.
}
\description{
Simple function for hyper-parameter tuning using k-fold cross-validation.
}
\examples{
N <- 2000
p <- 5

s <- seq(0, pi, length.out = N)
X <- matrix(NA, ncol = p, nrow = N)
X[, 1] <- sin(s)
X[, 2] <- cos(s)
X[, 3] <- s
X[, 4] <- s^2
X[, 5] <- s^3

beta <- matrix(rnorm(p), ncol = 1) 
y <- X \%*\% beta + rnorm(N, 0, 1)

hyperparameters <- list(
    N_hidden = list(c(100, 100, 50, 50), c(100, 10, 10), c(100)), 
    lambda = exp(seq(-12, 4))
)

folds <- 20

\dontrun{
tune_hyperparameters(rwnn, X, y, folds, hyperparameters)
}
}
