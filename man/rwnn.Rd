% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rwnn.R
\name{rwnn}
\alias{rwnn}
\alias{rwnn.formula}
\title{Random weight neural networks}
\usage{
rwnn(formula, data = NULL, N_hidden = c(), lambda = NULL, control = list())

\method{rwnn}{formula}(formula, data = NULL, N_hidden = c(), lambda = NULL, control = list())
}
\arguments{
\item{formula}{A \link{formula} specifying features and targets used to estimate the parameters of the output layer.}

\item{data}{A data-set (either a \link{data.frame} or a \link[tibble]{tibble}) used to estimate the parameters of the output layer.}

\item{N_hidden}{A vector of integers designating the number of neurons in each of the hidden layers (the length of the list is taken as the number of hidden layers).}

\item{lambda}{The penalisation constant used when training the output layer.}

\item{control}{A list of additional arguments passed to the \link{control_rwnn} function.}
}
\value{
An \link{RWNN-object}.
}
\description{
Set-up and estimate weights of a random weight neural network.
}
\details{
The deep RWNN is handled by increasing the number of elements in the \code{N_hidden} vector.
}
\examples{
N <- 2000
p <- 5

s <- seq(0, pi, length.out = N)
X <- matrix(NA, ncol = p, nrow = N)
X[, 1] <- sin(s)
X[, 2] <- cos(s)
X[, 3] <- s
X[, 4] <- s^2
X[, 5] <- s^3

beta <- matrix(rnorm(p), ncol = 1) 
y <- X \%*\% beta + rnorm(N, 0, 1)

## Models with a single hidden layer
N_hidden <- 100
elm(y ~ X, N_hidden = N_hidden)
rwnn(y ~ X, N_hidden = N_hidden)

## Model with multiple hidden layers
N_hidden <- c(10, 20, 10, 5)
rwnn(y ~ X, N_hidden = N_hidden)
}
