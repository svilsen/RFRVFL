% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/boost_rwnn.R
\name{boost_rwnn}
\alias{boost_rwnn}
\alias{boost_rwnn.formula}
\title{Boosting random weight neural networks}
\usage{
boost_rwnn(
  formula,
  data = NULL,
  N_hidden = c(),
  lambda = NULL,
  B = 10,
  epsilon = 1,
  control = list()
)

\method{boost_rwnn}{formula}(
  formula,
  data = NULL,
  N_hidden = c(),
  lambda = NULL,
  B = 10,
  epsilon = 0.1,
  control = list()
)
}
\arguments{
\item{formula}{A \link{formula} specifying features and targets used to estimate the parameters of the output layer.}

\item{data}{A data-set (either a \link{data.frame} or a \link[tibble]{tibble}) used to estimate the parameters of the output layer.}

\item{N_hidden}{A vector of integers designating the number of neurons in each of the hidden layers (the length of the list is taken as the number of hidden layers).}

\item{lambda}{The penalisation constant used when training the output layers of each RWNN.}

\item{B}{The number of levels used in the boosting tree.}

\item{epsilon}{The learning rate.}

\item{control}{A list of additional arguments passed to the \link{control_rwnn} function.}
}
\value{
An \link{ERWNN-object}.
}
\description{
Use gradient boosting to create ensemble random weight neural network models.
}
\examples{
N <- 2000
p <- 5

s <- seq(0, pi, length.out = N)
X <- matrix(NA, ncol = p, nrow = N)
X[, 1] <- sin(s)
X[, 2] <- cos(s)
X[, 3] <- s
X[, 4] <- s^2
X[, 5] <- s^3

beta <- matrix(rnorm(p), ncol = 1) 
y <- X \%*\% beta + rnorm(N, 0, 1)

N_hidden <- 5
B <- 1000
epsilon <- 0.1
lambda <- 0.1

\dontrun{
boost_rwnn(y ~ X, N_hidden = N_hidden, 
           lambda = lambda, B = B, epsilon = epsilon)
}
}
